# replace weights_directory with either:
# * the *ABSOLUTE PATH* to where you store your weights, or
# * the huggingface repo with your weights
[llama-2-7b]
weights_directory = meta-llama/Llama-2-7b-hf
name = LLaMA-2-7B
tokenizer_class = LlamaTokenizer
model_class = LlamaForCausalLM
layers = model.layers
probe_layer = 13
intervene_layer = 7
noperiod = False

[llama-3-8b]
weights_directory = /home/jiajun/.cache/huggingface/hub/models--meta-llama--Llama-3-8b-hf
name = LLaMA-3-8B
tokenizer_class = AutoTokenizer
model_class = AutoModelForCausalLM
layers = model.layers
probe_layer = 13
intervene_layer = 7
noperiod = False

[hf_key]
hf_key = PLACEHOLDER